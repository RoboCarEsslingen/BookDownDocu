[
["index.html", "RoboCar project documentation Chapter 1 Project RoboCar", " RoboCar project documentation Uwe Sterr 2018-12-03 Chapter 1 Project RoboCar We want to build autonomous driving model cars which can master a course without any human intervention The project was started during one of those cold dark winter evenings on 8th of February 2018 by Elias, who carried this idea with him for quite some time already Andreas, who as far as I can tell is interested in just about everything Finn, who probably never thought about this idea before that day but was immediately enthusiastic Uwe, who was infected with the idea by Elias in autumn 2017 We decided then and there to build autonomous robotic cars probably with Raspberry Pi, but open for all possible concepts. We organize our meetings via the meetup group https://www.meetup.com/Esslingen-Makerspace/, you are welcome to join in, register as a member of that meetup group and you will receive invitations to our meetings. This documentation shall act as an archive for Resources Experiences gathered Theory Minutes of meeting For inspiration you can check the it:movES http://www.hs-esslingen.de/de/hochschule/fakultaeten/informationstechnik/aktuelles/einzelansicht/datum/2018/02/artikel/carolo-cup-2018-itmoves-belegt-vorderen-platz.html &lt; "],
["resources.html", "Chapter 2 Resources 2.1 Meetups 2.2 RoboCar projects 2.3 Hardware 2.4 Simulators 2.5 Software", " Chapter 2 Resources In this section interesting resources for different topics are listed 2.1 Meetups 2.1.1 Esslinger Makerspace Projekt: Autonomen RoboCar bauen https://www.meetup.com/Esslingen-Makerspace/ Ob ihr euer eigenes RoboCar entwickeln wollt, oder lieber ein kleines Team bilden wollt, hier seit ihr richtig. 2.1.2 Autonomous Mobility Berlin https://www.meetup.com/autonomous-mobility-berlin/ This is a group for anyone interested and intrigued by Autonomous Mobility, Self-Driving Cars (SDC). Robots. We will cover topics on related technologies - Computer Vision, Deep Learning, Reinforcement learning, evolutionary computation, Sensor Fusion, ROS etc.. 2.2 RoboCar projects 2.2.1 DIY RoboCars https://diyrobocars.com/about/ This is the sister site to DIY Drones and resource/community companion to the DIY Robocars Meetup Group. Created by Chris Anderson of 3DR. 2.2.2 Donkey car http://www.donkeycar.com An opensource DIY self driving platform for small scale cars. RC CAR + Raspberry Pi + Python (tornado, keras, tensorflow, opencv, ….) The documentation of the project includes: Assemble hardware. Install software. Calibrate your car. Start driving. Train an autopilot. Experiment with simulator The code can be found at github 2.2.3 Sunfounder Smart Video Car Kit for Raspberry Pi with Android App https://www.sunfounder.com/robotic-drone/smartcar/smart-video-car-kit/rpi-car.html This is a complete learning kit based on Raspberry Pi with Android App. For better learning, an elaborately-written user manual, code with explanation and thorough schematic diagrams are provided. Available at amazon Sunfounder software is found at github Documentation can be found at https://www.sunfounder.com/learn/category/Smart-Video-Car-V2-0-for-Raspberry-Pi-Pi-Car-V.html 2.2.4 Kuman Professional WIFI Smart Robot Model Car Kit Videokamera for Raspberry Pi 3 Einfache Montage und Bedienung: Das ist ein komplettes WIFI-Lern-Smart-Roboter-Kit mit 8GB-Karte basierend auf Raspberry Pi 3 Controlled by ISO Android App. Für den Betrieb leicht, Code of smart Robot System sind in 8 GB Karte vorinstalliert. Für ein besseres Lernen, eine ausführliche schriftliche Benutzerhandbuch, Code mit Erklärung und schematische Diagramme werden von kuman zur Verfügung gestellt. Available at amazon 2.3 Hardware In this section hardware related information is presented 2.3.1 KOMPONENTENLISTE FÜR EIN FERNGESTEUERTES ROBOTER AUTO https://custom-build-robots.com/raspberry-pi-roboter-auto-komponenten Ingmar Stapel from Munich keeps this list up to date ROBOTER AUTO GEHIRN – RASPBERRY PI 3 MODEL B RASPBERRY PI – KAMERAS IM ÜBERBLICK MOTORTREIBER L298N H-BRÜCKE STEP-DOWN CONVERTER (MEINE EMPFEHLUNG) MOTOREN 2.3.2 Motor control How to control steer and throttle 2.3.2.1 PCA9685 2.3.2.1.1 16-KANAL PCA9685 SERVO KONTROLLER – TEIL 1 EINFÜHRUNG UND AUFBAU https://custom-build-robots.com/raspberry-pi-elektronik/16-kanal-pca9685-servo-kontroller-i2c-schnittstelle-einfuehrung-aufbau/8040 16 channels From Adafruit Connect to Raspberry via I2C 3.3V supply For motor control together with L298N H-bridge Table 2.1: Wiring PCA9685 Raspberry Pi Raspberry_Pi Servo_Driver Pin 1 (3,3 V) VCC Pin 6 (GND) GND GPIO 2 (SDA) SDA GPIO 3 (SCL) SCL 2.3.2.1.2 Adafruit 16 Channel Servo Driver with Raspberry Pi https://learn.adafruit.com/adafruit-16-channel-servo-driver-with-raspberry-pi/overview Good explanation with link to github code and wiring example 2.3.2.2 Wii sensor Could use wii sensor instead of camera 2.4 Simulators 2.4.1 Donkey Simulator http://docs.donkeycar.com/guide/simulator/ Experiment with training a donkey car to drive in simulation. This simulator is built on the the Unity game platform, uses their internal physics and graphics, and connects to a donkey Python process to use our trained model to control the simulated Donkey. 2.5 Software 2.5.1 Udacitiy open source SDC https://github.com/udacity/self-driving-car At Udacity, we believe in democratizing education. How can we provide opportunity to everyone on the planet? We also believe in teaching really amazing and useful subject matter. When we decided to build the Self-Driving Car Nanodegree program, to teach the world to build autonomous vehicles, we instantly knew we had to tackle our own self-driving car too. Together with Google Self-Driving Car founder and Udacity President Sebastian Thrun, we formed our core Self-Driving Car Team. One of the first decisions we made? Open source code, written by hundreds of students from across the globe! 2.5.2 connect raspberry with xbox controller good tutorial with example code https://tutorials-raspberrypi.de/raspberry-pi-xbox-360-controller-steuern/ you find a code example import RPi.GPIO as GPIO import math import xbox GPIO_LED_GREEN = 23 GPIO_LED_RED = 22 GPIO_LED_YELLOW = 27 GPIO_LED_BLUE = 17 GPIO_SERVO_PIN = 25 GPIO.setmode(GPIO.BCM) GPIO.setwarnings(False) GPIO.setup(GPIO_LED_GREEN, GPIO.OUT) GPIO.setup(GPIO_LED_RED, GPIO.OUT) GPIO.setup(GPIO_LED_YELLOW, GPIO.OUT) GPIO.setup(GPIO_LED_BLUE, GPIO.OUT) GPIO.setup(GPIO_SERVO_PIN, GPIO.OUT) def updateServo(pwm, angle): duty = float(angle) / 10.0 + 2.5 pwm.ChangeDutyCycle(duty) def angleFromCoords(x,y): angle = 0.0 if x==0.0 and y==0.0: angle = 90.0 elif x&gt;=0.0 and y&gt;=0.0: # first quadrant angle = math.degrees(math.atan(y/x)) if x!=0.0 else 90.0 elif x&lt;0.0 and y&gt;=0.0: # second quadrant angle = math.degrees(math.atan(y/x)) angle += 180.0 elif x&lt;0.0 and y&lt;0.0: # third quadrant angle = math.degrees(math.atan(y/x)) angle += 180.0 elif x&gt;=0.0 and y&lt;0.0: # third quadrant angle = math.degrees(math.atan(y/x)) if x!=0.0 else -90.0 angle += 360.0 return angle if __name__ == &#39;__main__&#39;: joy = xbox.Joystick() pwm = GPIO.PWM(GPIO_SERVO_PIN, 100) pwm.start(5) while not joy.Back(): # LEDs led_state_green = GPIO.HIGH if joy.A() else GPIO.LOW led_state_red = GPIO.HIGH if joy.B() else GPIO.LOW led_state_yellow = GPIO.HIGH if joy.Y() else GPIO.LOW led_state_blue = GPIO.HIGH if joy.X() else GPIO.LOW GPIO.output(GPIO_LED_GREEN, led_state_green) GPIO.output(GPIO_LED_RED, led_state_red) GPIO.output(GPIO_LED_YELLOW, led_state_yellow) GPIO.output(GPIO_LED_BLUE, led_state_blue) # Servo x, y = joy.leftStick() angle = angleFromCoords(x,y) if angle &gt; 180 and angle &lt; 270: angle = 180 elif angle &gt;= 270: angle = 0 updateServo(pwm, angle) joy.close() pwm.stop() 2.5.3 RASPBERRY PI RC CONTROL http://www.instructables.com/id/Raspberry-Pi-RC-Control/ 2.5.4 Python class to support xbox 360 controller under Linux on RaspberryPi Python class to support reading xbox 360 wired and wireless controller input under Linux. Makes it easy to get real-time input from controller buttons, analog sticks and triggers. Built and tested on RaspberryPi running Raspbian. code example import xbox joy = xbox.Joystick() #Initialize joystick if joy.A(): #Test state of the A button (1=pressed, 0=not pressed) print &#39;A button pressed&#39; x_axis = joy.leftX() #X-axis of the left stick (values -1.0 to 1.0) (x,y) = joy.leftStick() #Returns tuple containing left X and Y axes (values -1.0 to 1.0) trigger = joy.rightTrigger() #Right trigger position (values 0 to 1.0) joy.close() #Cleanup before exit https://github.com/FRC4564/Xbox 2.5.5 xbox driver for mac https://github.com/360Controller/360Controller/releases 2.5.6 Konzept für softwareschichten Die Softwareschichten sollen es ermöglichen das teile der software zwischen den bastlern ausgetauscht werden können bzw. unabhängig voneinander entwickelt werden können Arduino comm schicht actor schicht input geschwindigkeit cm/s resolution TBD lenkwinkel grad resolution 0.1 degree sensor schicht ultraschall Raspi comm schicht actor schicht arduino USB seriell oder I2C auf PCA wlan/USB für den controller TCP/IP wlan für streaming des videos SAMBA zum auslesen des USB sticks sensor schicht kamera neuronales netz/ oder läuft auf PC USB stick für trainingsdatenaufzeichnung output geschwindigkeit cm/s resolution TBD lenkwinkel grad resolution 0.1 degree input über WLAN vom Laptop geschwindigkeit cm/s resolution TBD lenkwinkel grad resolution 0.1 degree Laptop comm schicht controller USB stick auslesen verbindung zum Raspberry data pre-processing sensor data camera data downsampling color scheme neuronales netz training output geschwindigkeit cm/s resolution TBD lenkwinkel grad resolution 0.1 degree TBC "],
["experiences.html", "Chapter 3 Experiences gathered 3.1 Install donkey car on Mac 3.2 Donkey car simulator", " Chapter 3 Experiences gathered Here I will write down how the adventure goes 3.1 Install donkey car on Mac http://docs.donkeycar.com/guide/install_software/#install-donkeycar-on-mac Installation went without problem. Note: After closing the Terminal, when you open it again, you will need to type source activate donkey to re-enable the mappings to donkey specific Python libraries 3.2 Donkey car simulator http://docs.donkeycar.com/guide/simulator/ Typical Use Start simulator Double check that log dir exists and is empty Start scene of your choice Hit Auto Drive w Rec button Vary the Max Speed, Prop, and Diff sliders to obtain a variety of driving styles Wait 10-15 minutes until you have recorded 10K+ frames of data. Hit the Stop button Hit the Exit button Move the log dir to the ~/d2/data/ dir where you normally put tub data. - This will create a ~/d2/data/log path. Train as usual. "],
["Theory.html", "Chapter 4 Theory 4.1 Wiring of PCA9685 with L298N H-bridge 4.2 sensor fusion of LIDAR and camera data", " Chapter 4 Theory This section is a collection of theory and concepts 4.1 Wiring of PCA9685 with L298N H-bridge Since the raspberry pi PWM signal is not very stable the I2C interface is used to connect to to the servo driver PCA9685. If a higher voltage is needed the motor driver L298N H-bridge can be utilized. Each H-Bridge requires two additional signals: turn motor CW turn motor CCW no signal =&gt; motor brakes https://www.npmjs.com/package/node-red-contrib-pca9685 4.2 sensor fusion of LIDAR and camera data Paper by Varuna De Silva, Jamie Roche, and Ahmet Kondoz, Senior Member, IEEE Fusion of LiDAR and Camera Sensor Data for Environment Sensing in Driverless Vehicles This paper addresses the problem of fusing the outputs of a LiDAR scanner and a wide-angle monocular image sensor. The first part of the proposed framework spatially aligns the two sensor data streams with a geometric model. The resolutions of the two sensors are quite different, with the image sensor having a much denser spatial resolution. https://arxiv.org/pdf/1710.06230.pdf "],
["robocarLogBook.html", "Chapter 5 RoboCar Logbook 5.1 15-02-2018 5.2 Build sunfounder car 17-02-2018 5.3 Viewing a list of available Python versions 5.4 Run calibration 5.5 MJPG-streamer Installation", " Chapter 5 RoboCar Logbook The logbook shall be the place to log activities so that future me will understand what present me was doing and maybe even why. 5.1 15-02-2018 Already installed donkey software on mac at /Users/uwesterr/miniconda3/envs/donkey according to http://docs.donkeycar.com/guide/install_software/#install-donkeycar-on-mac 5.1.1 donkey findcar the command donkey findcar leads to sudo: nmap: command not found therefore nmap shall be installed using sudo apt install nmap this leads to error message Unable to locate an executable at &quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/bin/apt&quot; (-1) 5.2 Build sunfounder car 17-02-2018 took about 4h, very good instructions at https://www.sunfounder.com/learn/download/U21hcnRfVmlkZW9fQ2FyX2Zvcl9SYXNwYmVycnlfUGkucGRm/dispi 5.2.1 install software 18-02-2018 download RASPBIAN STRETCH LITE from https://www.raspberrypi.org/downloads/raspbian/ use Etcher to flash SD card for raspi and put SD card in adapter to put into card reader of mac book Create a blank file ssh under the /boot directory to enable remote login and delete the suffix in the file name. Create a WiFi configuration file wpa_supplicant.conf under /boot according to http://www.linux-ratgeber.de/wlan-verbindungsdaten-einrichten-ueber-die-wpa_supplicant-conf/ ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=“WLAN-NAME_1” psk=“WLAN-SCHLUESSEL_1” proto=RSN scan_ssid=1 key_mgmt=WPA-PSK pairwise=CCPM group=TKIP } 5.2.1.1 boot up raspi username: pi password: raspberry change password type passwd and follow instructions change to german keyboard layout sudo nano /etc/default/keyboard find where it says XKBLAYOUT=”gb” to XKBLAYOUT=”de” and change the gb to the two letter code for german pipe symbol | =&gt; alt option + &lt; Get Source Code sudo apt-get install git git clone https://github.com/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi.git Install python-dev, python-smbus sudo apt-get update sudo apt-get upgrade sudo apt-get install python-dev sudo apt-get install python-smbus Setup I2C Port sudo raspi-config could not get wlan to work install now RASPBIAN STRETCH WITH DESKTOP instead RASPBIAN STRETCH LITE hostnam uwesCar do the follwoing steps again Get Source Code sudo apt-get install git git clone https://github.com/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi.git Install python-dev, python-smbus sudo apt-get update sudo apt-get upgrade sudo apt-get install python-dev sudo apt-get install python-smbus Setup I2C Port done this time in pixel desktop Start calibration cd ~/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/server sudo python cali_server.py set wlan sudo nano /etc/wpa_supplicant/wpa_supplicant.conf sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Run cali_client cali_client.py is written in python2, i got python 3 installed changed cali_client.py added parenthesis for print statements Python 3 calls it tkinter not Tkinter. run sudo python cali_client.py leads to Exception in Tkinter callback Traceback (most recent call last): File &quot;/Users/uwesterr/miniconda3/lib/python3.6/tkinter/__init__.py&quot;, line 1699, in __call__ return self.func(*args) File &quot;cali_client.py&quot;, line 56, in left_reverse tcpCliSock.send(left_cmd) TypeError: a bytes-like object is required, not &#39;str&#39; therefore build an environment with python 2 conda create --name sunfounder gives Package plan for installation in environment /Users/uwesterr/miniconda3/envs/sunfounder: To activate this environment, use: &gt; source activate sunfounder To deactivate an active environment, use: &gt; source deactivate python –version Python 3.6.0 :: Continuum Analytics, Inc. 5.3 Viewing a list of available Python versions To list the versions of Python that are available to install, in your Terminal window or an Anaconda Prompt, run: conda search python This lists all packages whose names contain the text python. To list only the packages whose full name is exactly python, add the –full-name option. In your Terminal window or an Anaconda Prompt, run: conda search --full-name python conda search –full-name python build environment with python 2.7 conda create -n sunfounderPy27 python=2.7 anaconda To activate this environment, use: source activate sunfounderPy27 To deactivate an active environment, use: source deactivate Uwes-MBP:~ uwesterr$ source activate sunfounderPy27 (sunfounderPy27) Uwes-MBP:~ uwesterr$ python –version Python 2.7.13 :: Anaconda 4.4.0 (x86_64) raspberry ip 192.168.178.67 5.4 Run calibration on raspbeery cd ~/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/server sudo python cali_server.py on mac source activate sunfounderPy27 cd /Users/uwesterr/CloudProjectsUnderWork/ProjectsUnderWork/RoboCar/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/client sudo python cali_client.py 5.5 MJPG-streamer Installation Installation Plug the USB camera into Raspberry Pi, and run the command lsusb. The GEMBIRD represents the USB camera; since it is printed on the screen, it indicates the system has recognized the camera. lsusb resutls in Bus 001 Device 004: ID 1908:2310 GEMBIRD Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Check whether the driver for the camera works normally: ls /dev/vid* ls /dev/vid* results in /dev/video0 install the following software sudo apt-get install subversion sudo apt-get install libv4l-dev sudo apt-get install libjpeg8-dev sudo apt-get install imagemagick Compile the source code of MJPG-streamer: cd /home/pi/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/mjpg-streamer/mjpg-streamer sudo make USE_LIBV4L2=true clean all Install: sudo make DESTDIR=/usr install 5.5.1 Testing Operation on Raspberry Pi Run the program: sudo sh start.sh on Mac Type in the following address at the address bar of your browser (Firefox is recommended): http://192.168.178.67:8080/stream.html "],
["get-on-the-road.html", "Chapter 6 Get on the Road! 6.1 install carnd-term1 6.2 Install Xbox 360 controller 6.3 Implement Xbox controller as input in client_App.py 6.4 Get IP adress of raspi 6.5 Store snapshots of video stream on local computer", " Chapter 6 Get on the Road! Use two terminals for raspberry first teminal run jgp streamer cd /home/pi/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/mjpg-streamer/mjpg-streamer sudo sh start.sh second terminal run tcp_server.py: cd ~/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/server sudo python tcp_server.py on mac terminal in environment sunfounderPy27 Type in the following address at the address bar of your browser (Firefox is recommended): http://192.168.178.67:8080/stream.html source activate sunfounderPy27 or if openCV is needed source activate carnd-term1 6.1 install carnd-term1 git clone https://github.com/udacity/CarND-Term1-Starter-Kit.git cd CarND-Term1-Starter-Kit conda env create -f environment.yml conda install -c anaconda tk cd /Users/uwesterr/CloudProjectsUnderWork/ProjectsUnderWork/RoboCar/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/client sudo python client_App.py 6.2 Install Xbox 360 controller install Xbox 360 controller drive on mac https://github.com/360Controller/360Controller/releases NOTE!!! it seems necessary to have the controller plugged into the USB port during boot up According to http://www.philipzucker.com/python-xbox-controller-mac/ Install pygame python -m pip install -U pygame --user or brew upgrade sdl sdl_image sdl_mixer sdl_ttf portmidi python3.6 -m venv anenv . ./anenv/bin/activate pip install https://github.com/pygame/pygame/archive/master.zip create a jupyter notebook “xboxControllerOnMac.ipynb”&quot; with import pygame import sys import time import socket import cPickle as pickle UDP_IP = &quot;127.0.0.1&quot; UDP_PORT = 5005 MESSAGE = &quot;Hello, World!&quot; print &quot;UDP target IP:&quot;, UDP_IP print &quot;UDP target port:&quot;, UDP_PORT print &quot;message:&quot;, MESSAGE sock = socket.socket(socket.AF_INET, # Internet socket.SOCK_DGRAM) # UDP pygame.init() pygame.joystick.init() clock = pygame.time.Clock() print pygame.joystick.get_count() _joystick = pygame.joystick.Joystick(0) _joystick.init() gives: UDP target IP: 127.0.0.1 UDP target port: 5005 message: Hello, World! 1 watch out for the “1” which indicates that the controller was identified while 1: for event in pygame.event.get(): if event.type == pygame.JOYBUTTONDOWN: print(&quot;Joystick button pressed.&quot;) print event if event.type == pygame.JOYAXISMOTION: #print _joystick.get_axis(0) #print event if event.axis == 0: # this is the x axis print event.value if event.axis == 5: # right trigger print event.value xdir = _joystick.get_axis(0) rtrigger = _joystick.get_axis(5) #deadzone if abs(xdir) &lt; 0.2: xdir = 0.0 if rtrigger &lt; -0.9: rtrigger = -1.0 MESSAGE = pickle.dumps([xdir,rtrigger]) sock.sendto(MESSAGE, (UDP_IP, UDP_PORT)) clock.tick(30) when using controller the following output was created 0.00781273842586 -1.00003051851 Joystick button pressed. 0.0 0.00781273842586 Joystick button pressed. 0.0312509537034 6.3 Implement Xbox controller as input in client_App.py In client_App.py the part for driving forward extracted from Tkinter import * from socket import * # Import necessary modules ctrl_cmd = [&#39;forward&#39;, &#39;backward&#39;, &#39;left&#39;, &#39;right&#39;, &#39;stop&#39;, &#39;read cpu_temp&#39;, &#39;home&#39;, &#39;distance&#39;, &#39;x+&#39;, &#39;x-&#39;, &#39;y+&#39;, &#39;y-&#39;, &#39;xy_home&#39;] top = Tk() # Create a top window top.title(&#39;Sunfounder Raspberry Pi Smart Video Car&#39;) HOST = &#39;192.168.178.67&#39; # Server(Raspberry Pi) IP address PORT = 21567 BUFSIZ = 1024 # buffer size ADDR = (HOST, PORT) tcpCliSock = socket(AF_INET, SOCK_STREAM) # Create a socket tcpCliSock.connect(ADDR) # Connect with the server # ============================================================================= # The function is to send the command forward to the server, so as to make the # car move forward. # ============================================================================= def forward_fun(event): print &#39;forward&#39; tcpCliSock.send(&#39;forward&#39;) then keystrokes are binded to the forward function, this needs to be changed to bind Xbox controller values to the function # ============================================================================= # Bind buttons on the keyboard with the corresponding callback function to # control the car remotely with the keyboard. # ============================================================================= top.bind(&#39;&lt;KeyPress-w&gt;&#39;, forward_fun) # Press down key &#39;w&#39; on the keyboard and the car will drive forward. from https://github.com/martinohanlon/XboxController/blob/master/XboxController.py JOYAXISMOTION event.axis event.value 0 - x axis left thumb (+1 is right, -1 is left) 1 - y axis left thumb (+1 is down, -1 is up) 2 - x axis right thumb (+1 is right, -1 is left) 3 - y axis right thumb (+1 is down, -1 is up) 4 - right trigger 5 - left trigger JOYBUTTONDOWN | JOYBUTTONUP event.button A = 0 B = 1 X = 2 Y = 3 LB = 4 RB = 5 BACK = 6 START = 7 XBOX = 8 LEFTTHUMB = 9 RIGHTTHUMB = 10 6.3.1 Make steering proportional to remote control lever position change code from if event.axis == 0: # this is the x axis if event.value &gt; thresSteerHigh: tcpCliSock.send(&#39;right&#39;) if event.value &lt; thresSteerLow: tcpCliSock.send(&#39;left&#39;) to if event.axis == 0: # this is the x axis if event.value &gt; thresSteerHigh: tcpCliSock.send(&#39;right&#39;) angle = int(100*abs(event.value)) data = tmp1 + str(angle) print &#39;sendData = %s&#39; % data tcpCliSock.send(data) # Send the speed data to the server(Raspberry Pi) if event.value &lt; thresSteerLow: tcpCliSock.send(&#39;left&#39;) angle = int(-100*abs(event.value)) data = tmp1 + str(angle) print &#39;sendData = %s&#39; % data tcpCliSock.send(data) # Send the speed data to the server(Raspberry Pi) 6.4 Get IP adress of raspi Check in the router for the IP adress, procedure is dependent on router At shackspace go to http://leases.shack/#/ (only available from the shackspace network) and then connect via ssh pi@ipAdress 6.5 Store snapshots of video stream on local computer Donkey car stores training data on raspi SD card. In this concept the XBox controller is connected via USB to a laptop (in my case a Mac) and it makes sense to store the traing data on the laptop as well since we anyway will train the NN on that machine. The URL of the stream is: *url = “http://10.42.26.33:8080/?action=stream&quot;* for a snapshot the URL is *url = “http://10.42.26.33:8080/?action=snapshot&quot;* check video https://youtu.be/2xcUzXataIk?t=556 for a good explanation of how to receive an IP video stream. Based on that tutorial the follwing code now stores a single frame and shows that frame as well. import cv2 import numpy as np import urllib # based on example in https://www.youtube.com/watch?v=2xcUzXataIk url = &quot;http://192.168.178.67:8080/?action=snapshot&quot; imgNp = np.array(bytearray(imgResp.read()), dtype = np.uint8) img = cv2.imdecode(imgNp,-1) cv2.imshow(&quot;test&quot;,img) cv2.imwrite( &quot;Snapshot.jpg&quot;, img ); cv2.waitKey(10000) 6.5.1 Jie Hou’s alternative Jie has another solution for the same task, see https://drive.google.com/drive/folders/10U8ZTr_2HVnBWrFqvVFGO0UyQn0vCmiE The code is import cv2 import numpy as np try: from urllib.request import urlopen except ImportError: from urllib2 import urlopen print(&#39;# capture image from video #&#39;) stream = urlopen(&#39;http://192.168.0.101:8080/?action=stream&#39;) bytes = bytes() FlagSaveImage = 0 while True: bytes += stream.read(1024) a = bytes.find(b&#39;\\xff\\xd8&#39;) b = bytes.find(b&#39;\\xff\\xd9&#39;) print(&#39; #a: &#39;, a, &#39; ,b: &#39;, b) if a != -1 and b != -1: jpg = bytes[a: b + 2] bytes = bytes[b+2:] image = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.imshow(&#39;image&#39;, image) if FlagSaveImage == 0: cv2.imwrite(&#39;test.jpg&#39;, image) FlagSaveImage = 1 if cv2.waitKey(1) == 27: exit(0) "],
["donkeyCar.html", "Chapter 7 Change to donkeycar 7.1 Reason for changing the plattform 7.2 What to do", " Chapter 7 Change to donkeycar In December 2018 I switched from sunfounder to donkeycar Donkey Car 7.1 Reason for changing the plattform The sunfounder was wonderful to learn the basics, PWM, I2C, use of camera with Pi, but had shortcommings in the steering mechanism. The steering angle was not reproducable, i.e. sending twice the same steering command did result in different steering angles of about a few degrees difference. Now since the aim of the game is to train a neural net which takes the commanded steering angle as ground truth this was a show stopper for me and therefore i moved to =&gt; Donkey Car Second reason, other members of the group Esslinger Makerspace Projekt: Autonomen RoboCar bauen opted for donkey car. I changed to Reely Dart 2.0 Brushed Tamiya-Buchse is the connector of the NiMH battery Charger is Voltcraft V-Charge Eco NiMh 3000 7.2 What to do disassemble the sunfounder, by taking of the plate on which the raspberry is mounted disassemble the L298N H-bridge, not needed if you use an ESC connect the [PWM] signal of your PCA9685 to the new car channel 0 =&gt; steering channel 1 =&gt; throttle Install Software on Pi and Host Computer Setup RaspberryPi Setup Mac Host PC (or windows or linux host) Calibrate your car Drive your car Train an autopilot with Keras http://docs.donkeycar.com/guide/simulator/ Select web or pysical controller Controller Parts 7.2.1 Folders created during installation of host PC /Users/uwesterr/mycar/models /Users/uwesterr/mycar/data /Users/uwesterr/mycar/logs Note, there seems to be an issue with driving two servos with PCA9685 at the same time. What happens is that steering and throttle work during calibartion but not when the car is controlled via the web interface. TBC A possible cure is described at Adafruit 16 Channel Servo Driver with Raspberry Pi. When to add an optional Capacitor to the driver board We have a spot on the PCB for soldering in an electrolytic capacitor. Based on your usage, you may or may not need a capacitor. If you are driving a lot of servos from a power supply that dips a lot when the servos move, n * 100uF where n is the number of servos is a good place to start - eg 470uF or more for 5 servos. Since its so dependent on servo current draw, the torque on each motor, and what power supply, there is no “one magic capacitor value” we can suggest which is why we don’t include a capacitor in the kit. I did not check whether this works. For RPI SERVO HAT that problem was not seen. SETTING WIFI UP VIA THE COMMAND LINE "],
["minutesOfMeeting.html", "Chapter 8 Minutes of meeting 8.1 21-03-2018 8.2 15-02-2018 8.3 08-02-2018", " Chapter 8 Minutes of meeting In this section short minutes of meetings are kept so that people who join later can easily get up to speed 8.1 21-03-2018 Discussing concept, elias volunteered to create block diagram Trying to get Xbox 360 controller to work with raspi and mac, failed since controller was not accessable from python eventhough it was accessable on the mac via system preference pane. 8.2 15-02-2018 8.2.1 Plattformen 8.2.1.1 Sunfounder link für amazon bestellung https://www.amazon.de/SunFounder-Roboterbausatz-Programmierbarer-Auto-Roboter-Compatible/dp/B01ANIY3EC/ref=sr_1_1?ie=UTF8&amp;qid=1518719324&amp;sr=8-1&amp;keywords=sunfounder 8.2.1.2 Basis Donkey car http://www.donkeycar.com/ http://docs.donkeycar.com/ http://docs.donkeycar.com/guide/build_hardware/ https://makezine.com/projects/build-autonomous-rc-car-raspberry-pi/ https://diyrobocars.com/ * Kinect / Wii https://sungjik.wordpress.com/2015/09/28/my_personal_robotic_companion/ Basis Carputer https://github.com/otaviogood/carputer 8.2.1.3 Openzeka https://www.youtube.com/results?search_query=openzeka 8.2.2 neuronales Netz 8.2.2.1 Hardware Nvida Jetson TX2 paralella 8.2.2.2 kontakt Slack channel: donkeycar.slack.com meetup 8.3 08-02-2018 8.3.1 Location: Shackspace What was meant to be a an introduction into the shackspace evolved to a discussion about various topics 8.3.2 Studie Hackerspaces http://www.cowerk.org/home/single/article/befragungsergebnisse-wertschoepfung-in-offenen-werkstaetten.html https://www.heise.de/make/meldung/Studie-Neue-Produktionsmodelle-in-offenen-Werkstaetten-3504625.html https://www.heise.de/make/meldung/Kein-Freifahrtschein-fuer-Hackerspaces-Benutzung-auf-eigene-Gefahr-3955181.html 8.3.3 Buchtipps Makers: Das Internet der Dinge: die nächste industrielle Revolution, Chris Anderson Zero Thinking fast and slow, Kahnemann Gunter Dueck https://www.omnisophie.com Vorträge auf der Re-publica als Einstieg https://www.youtube.com/results?search_query=gunter+dueck Biohacking: Gentechnologie für alle, Rüdiger Trojok Biohacking: Gentechnik aus der Garage, Hanno Charisius 8.3.4 RoboCar Elias says he would like to be build an autonomous model car, probably based on Raspberry Pi. In order to end dreaming and start doing we fixed the next meeting to 15th of February where we want to start defining concepts. "],
["useful-links.html", "Chapter 9 Useful links", " Chapter 9 Useful links config PI wifi Self-driving car in a simulator with a tiny neural network Esslinger Makerspace Projekt: Autonomen RoboCar bauen Reely Dart 2.0 Brushed ESC donkey car - Calibrate your car - Drive your car - Train an autopilot with Keras - http://docs.donkeycar.com/guide/simulator/ - Controller Parts Adafruit 16 Channel Servo Driver with Raspberry Pi RPI SERVO HAT SETTING WIFI UP VIA THE COMMAND LINE Install XBox driver on mac Python Xbox Controller Mac find IP adress in shack "]
]
